{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimential Scoring Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Previous Package + Reading in the Model Fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import string\n",
    "#import spacy\n",
    "import re\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,n_jobs=-1):\n",
    "        self.n_jobs = n_jobs\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        lower_case_text       = X.apply(lambda x:x.lower())\n",
    "        removed_punct_text    = lower_case_text.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "        removed_numbers_text  = removed_punct_text.apply(lambda x: re.sub(\" \\d+\", \" \", x))\n",
    "        clear_whitespace_text = removed_numbers_text.apply(lambda x: re.sub(' +', ' ', x.lstrip().rstrip()))\n",
    "        return clear_whitespace_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SelectKBest from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filename = 'LR_model.pkl'\n",
    "lr_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Table for Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year12 = []\n",
    "period12 = []\n",
    "for i in range(1979, 2021):\n",
    "    for j in range(0, 12):\n",
    "        year12.append(i)\n",
    "        period12.append(j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['positive', 'neutral', 'negative', 'exception']\n",
    "sentiment_score = pd.DataFrame(np.zeros((len(year12), len(column_name))), index = [year12, period12], columns = column_name)\n",
    "sentiment_score = sentiment_score.reset_index().rename(columns={\"level_0\": \"year\", \"level_1\": \"month\"}).set_index(['year','month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the List of files + Reading in the Text + Sentiment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 1 / 2942 ; doc_count = 11 / 100226Save csv....\n",
      "\n",
      "gdelt_list_counter = 2 / 2942 ; doc_count = 11 / 107131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 7 / 2942 ; doc_count = 7 / 607332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 10 / 2942 ; doc_count = 13 / 122642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (8,11,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 11 / 2942 ; doc_count = 12 / 115278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (14,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 13 / 2942 ; doc_count = 8 / 79812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (26,27,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 31 / 2942 ; doc_count = 14 / 130311Save csv....\n",
      "\n",
      "gdelt_list_counter = 43 / 2942 ; doc_count = 6 / 1532040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "gdelt_list_counter = 43 / 2942 ; doc_count = 7 / 153204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 43 / 2942 ; doc_count = 13 / 153204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "gdelt_list_counter = 43 / 2942 ; doc_count = 14 / 153204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "gdelt_list_counter = 43 / 2942 ; doc_count = 15 / 153204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 47 / 2942 ; doc_count = 3 / 2308706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (8,10,11,14,18,21,23,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 49 / 2942 ; doc_count = 2 / 19998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (11,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 51 / 2942 ; doc_count = 3 / 72614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 61 / 2942 ; doc_count = 5 / 460504Save csv....\n",
      "\n",
      "gdelt_list_counter = 67 / 2942 ; doc_count = 1 / 8705963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "gdelt_list_counter = 67 / 2942 ; doc_count = 2 / 87059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "gdelt_list_counter = 67 / 2942 ; doc_count = 3 / 87059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "gdelt_list_counter = 67 / 2942 ; doc_count = 4 / 87059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "gdelt_list_counter = 67 / 2942 ; doc_count = 5 / 87059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdelt_list_counter = 80 / 2942 ; doc_count = 11 / 104586"
     ]
    }
   ],
   "source": [
    "gdelt_list = pd.read_csv(r\"Data\\GDELT\\gdelt.csv\").set_index('filename')\n",
    "\n",
    "for gdelt_list_counter in range(0, len(gdelt_list)):\n",
    "    \n",
    "    zip_file_url = urlopen(gdelt_list.iloc[gdelt_list_counter]['hyperlink'])\n",
    "    zip_file = ZipFile(BytesIO(zip_file_url.read()))\n",
    "    document_list = pd.read_csv(zip_file.open(zip_file.namelist()[0]), sep ='\\t', header=None).set_index(0)\n",
    "    \n",
    "    for doc_count in range(0,len(document_list)):\n",
    "        \n",
    "        news_year = int(str(document_list.iloc[doc_count, 0])[0:4])\n",
    "        news_month = int(str(document_list.iloc[doc_count, 0])[4:6])\n",
    "        news_date = int(str(document_list.iloc[doc_count, 0])[6:8])\n",
    "\n",
    "        news_url = document_list.iloc[doc_count, -1]\n",
    "        try:\n",
    "            soup = BeautifulSoup(urlopen(news_url).read(), features=\"html.parser\")\n",
    "            for script in soup([\"script\", \"style\"]):    # kill all script and style elements\n",
    "                script.extract()\n",
    "            text = soup.get_text()    # get text\n",
    "            lines = (line.strip() for line in text.splitlines())    # break into lines and remove leading and trailing space on each\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))    # break multi-headlines into a line each\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)    # drop blank lines\n",
    "            sentiment = lr_model.predict(pd.Series(text))[0]\n",
    "        except:\n",
    "            sentiment = 'exception'\n",
    "\n",
    "        try:\n",
    "            sentiment_score.loc[(news_year, news_month), sentiment] += 1\n",
    "        except:\n",
    "            print('Error!')\n",
    "        \n",
    "        sys.stdout.write(\"\\rgdelt_list_counter = %s / %s ; doc_count = %s / %s\" % (gdelt_list_counter + 1, len(gdelt_list), doc_count + 1, len(document_list)))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    if gdelt_list_counter % 30 == 0:\n",
    "        print(\"Save csv....\\n\")\n",
    "        sentiment_score.to_csv(r\"Data\\sentiment_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score.to_csv(r\"Data\\sentiment_score.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
